# Cortex ğŸ§ ğŸš¨

![Cortex UI Demo](docs/cortex-ui.png)

Cortex is a **production incident knowledge copilot** that helps engineers quickly understand **why incidents happened** by querying historical **RCAs, runbooks, and operational documents**.

It provides **grounded, source-backed answers** using a **hybrid retrieval system** â€” without hallucinations and without relying on paid LLM APIs.

---

## âœ¨ What Cortex Does

- ğŸ” Answers production incident questions (timeouts, Kafka lag, DB exhaustion, CPU spikes, Redis outages)
- ğŸ“š Searches across historical RCAs and runbooks
- ğŸ§  Uses **hybrid retrieval (TF-IDF + semantic embeddings)**
- âš–ï¸ Ranks results using **weighted hybrid scoring**
- ğŸ›‘ Prevents hallucinations with strict grounding
- ğŸ§¾ Returns answers with **document-level source attribution**
- ğŸ’¸ Fully offline, zero-cost setup

Example questions:
- *Why did the payment service timeout last quarter?*
- *How do we prevent cascading failures?*
- *Why did Kafka consumer lag occur?*
- *What happens if Redis goes down?*

---

## ğŸ—ï¸ Architecture Overview

```

PDF Documents
â†“
Text Extraction & Sanitization
â†“
Chunking with Overlap
â†“
TF-IDF Vectorization        Dense Embeddings
â†“                           â†“
FAISS Index (Lexical)   FAISS Index (Semantic)
â†“        â†“
Hybrid Retrieval + Weighted Ranking
â†“
FastAPI (/ask)
â†“
Grounded Answer + Sources

```

---

## ğŸ§  Design Principles

### Grounded answers only
Cortex never invents information. If an answer is not present in the knowledge base, it responds with:
```

Answer not found in knowledge base.

```

### No hallucinations by design
- No generative model produces facts
- Answers are derived strictly from retrieved documents

### Offline-first
- No OpenAI APIs
- No paid inference services
- Runs entirely on local infrastructure

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **FastAPI** â€“ API layer
- **FAISS** â€“ Vector similarity search
- **Scikit-learn (TF-IDF)** â€“ Lexical embeddings
- **Sentence-Transformers** â€“ Semantic embeddings (local)
- **NLTK** â€“ Tokenization
- **Uvicorn** â€“ ASGI server

---

## ğŸ“‚ Project Structure

```

cortex/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py          # FastAPI application
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_text.py  # PDF â†’ clean text
â”‚   â”œâ”€â”€ chunk_docs.py    # Chunking logic
â”‚   â”œâ”€â”€ build_index.py   # TF-IDF FAISS index
â”‚   â”œâ”€â”€ build_embedding_index.py  # Semantic FAISS index
â”‚   â””â”€â”€ retrieve.py      # Local retrieval tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ raw_pdfs/        # Sanitized PDFs
â”‚   â””â”€â”€ clean_text/      # Extracted text
â”œâ”€â”€ index/               # Generated locally (gitignored)
â”‚   â”œâ”€â”€ faiss.index
â”‚   â”œâ”€â”€ faiss_embeddings.index
â”‚   â””â”€â”€ metadata.pkl
â””â”€â”€ README.md

````

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Create virtual environment
```bash
python3 -m venv venv
source venv/bin/activate
````

### 2ï¸âƒ£ Install dependencies

```bash
python3 -m pip install -r requirements.txt
```

### 3ï¸âƒ£ Build indexes

```bash
python3 scripts/build_index.py
python3 scripts/build_embedding_index.py
```

### 4ï¸âƒ£ Run the API

```bash
uvicorn app.main:app --reload
```

---

## ğŸ”Œ API Usage

### Health Check

```http
GET /health
```

Response:

```json
{ "status": "ok" }
```

---

### Ask a Question

```http
POST /ask
Content-Type: application/json
```

Request:

```json
{
  "question": "Why did payment service timeout last quarter?"
}
```

Response:

```json
{
  "question": "Why did payment service timeout last quarter?",
  "answer": "The root cause involved traffic spikes, resource saturation, configuration limits, and slow downstream calls.",
  "sources": [
    "payment-timeout-rca.txt",
    "cascading-failure-runbook.txt"
  ]
}
```

---

## ğŸ§ª Hallucination Guardrail Example

Request:

```json
{
  "question": "What is the company refund policy?"
}
```

Response:

```json
{
  "answer": "Answer not found in knowledge base."
}
```

---

## ğŸ¯ Use Cases

* On-call engineers debugging incidents
* New team members learning from past outages
* SREs analyzing recurring failure patterns
* Backend engineers preparing postmortems

---

## ğŸ“Œ Future Improvements

* Integrate LLM APIs with optimized prompt engineering and context window management; modular backend supports pluggable data sources and retrieval strategies.
* Add evaluation harness for retrieval quality
* Optional local LLM summarization (guarded)
* Dockerize for deployment
* UI dashboard for search & analytics
* Role-based access control

---

## ğŸ§‘â€ğŸ’» Author

Built by **Bhargab Nath**

---

## â­ Why Cortex Matters

Cortex demonstrates how to build **production-safe AI systems** that:

* prioritize correctness over fluency
* avoid hallucinations by design
* apply IR + ML techniques responsibly